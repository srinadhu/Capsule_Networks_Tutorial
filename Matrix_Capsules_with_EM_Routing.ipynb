{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Matrix Capsules with EM Routing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "2khVcpQAZV6i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#To install the PyTorch 0.4\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q7o3rcRVbIJl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms, datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PSAB600tuVkq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def one_hot_transform(labels):\n",
        "    one_hot = torch.zeros(labels.size()+tuple([10])).scatter_(-1, labels, 1)\n",
        "    return one_hot \n",
        "  \n",
        "trainset = datasets.MNIST ( root='../data', train = True, download = True, transform = transforms.Compose([ transforms.Pad(2), \n",
        "                                                                                                            transforms.RandomCrop(28),\n",
        "                                                                                                            transforms.ToTensor() ]),\n",
        "                            target_transform = one_hot_transform)\n",
        "\n",
        "testset = datasets.MNIST ( root='../data', train = False, download = True, transform = transforms.Compose([ transforms.ToTensor() ]), target_transform = one_hot_transform)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader( trainset, batch_size = 32, shuffle = True, num_workers = 4)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader( testset, batch_size = 32, shuffle = False, num_workers = 4)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JP74jqt-ubXW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CapsLayer(nn.Module):\n",
        "    def __init__(self, type_=\"primary\", in_channels=32, out_channels=32, num_iterations=3, num_capsules=1, kernel_size=3, stride=2):\n",
        "        super(CapsLayer, self).__init__()\n",
        "        self.type_=type_\n",
        "        self.in_channels=in_channels\n",
        "        self.out_channels=out_channels\n",
        "        if type_==\"primary\":\n",
        "            self.kernel_size=kernel_size\n",
        "            self.stride=stride\n",
        "            self.conv=nn.Conv2d(in_channels, out_channels*17, \n",
        "                        kernel_size=1, stride=1, padding=0)\n",
        "        else:\n",
        "            self.num_iterations=num_iterations\n",
        "            self.kernel=torch.eye(kernel_size, kernel_size)\n",
        "            self.kernel=(self.kernel[:, None, :, None]*self.kernel[None, :, None, :]).view(1, -1, kernel_size, kernel_size)\n",
        "            self.kernel=self.kernel.expand(in_channels*17, -1, kernel_size, kernel_size)\\\n",
        "                        .contiguous().view(-1, 1, kernel_size, kernel_size).to(device)\n",
        "            self.in_channels=in_channels\n",
        "            self.out_channels=out_channels\n",
        "            self.kernel_size=kernel_size\n",
        "            self.route_weights = nn.Parameter(torch.randn(out_channels, in_channels, 4, 4)).to(device)\n",
        "            self.Ba=nn.Parameter(torch.randn(out_channels)).to(device)\n",
        "            self.Bu=nn.Parameter(torch.randn(out_channels)).to(device)\n",
        "            self.stride=stride\n",
        "            #self.kernel=torch.ones(in_channels*17, 1, kernel_size, kernel_size).to(device)\n",
        "                \n",
        "            \n",
        "            \n",
        "            \n",
        "    def forward(self, x):\n",
        "        if self.type_==\"primary\":\n",
        "            M=self.conv(x)\n",
        "            \n",
        "        elif self.type_==\"conv\":\n",
        "            x=F.conv2d(x, self.kernel, groups=self.in_channels*17,  stride=self.stride)\n",
        "            x=x.view(-1, self.in_channels*17, self.kernel_size**2, x.size(2), x.size(3))\n",
        "            k_square=x.size(2)\n",
        "            w=x.size(3)\n",
        "            num_caps_j=self.out_channels\n",
        "            num_caps_i=self.in_channels*k_square\n",
        "            \n",
        "            pose_i=x[:, :-self.in_channels, :, :, :].view(-1, self.in_channels, 4, \n",
        "                                                       4, x.size(2), x.size(3), x.size(4))\\\n",
        "                      .permute(0, 1, 4, 5, 6, 2, 3).contiguous()\n",
        "            #pose_i=x[:, :-self.in_channels, :, :].view(-1, self.in_channels, 4, \n",
        "            #                                           4, x.size(2), x.size(3))\\\n",
        "            #          .permute(0, 1, 4, 5, 2, 3).contiguous()\n",
        "            Ai=x[:, -self.in_channels:, :, :, :].view(-1, 1, num_caps_i, w, w, 1)\n",
        "            #Ai=x[:, -self.in_channels:, :, :].view(-1, 1, num_caps_i, w, w, 1)\n",
        "            \n",
        "            V=(pose_i[:, None, :, :, :, :, :, :] @ self.route_weights[None, :, :, None, None, None, :, :])\\\n",
        "                      .view(-1, num_caps_j, num_caps_i, w, w, 16)\n",
        "            #V=(pose_i[:, None, :, :, :, :, :] @ self.route_weights[None, :, :, None, None, :, :])\\\n",
        "            #          .view(-1, num_caps_j, num_caps_i, w, w, 16)\n",
        "            \n",
        "            R=torch.ones(V.size(0), V.size(1), V.size(2), V.size(3), V.size(4), 1).to(device)/num_caps_j\n",
        "            for t in range(self.num_iterations):\n",
        "                # M-step\n",
        "                R=R*Ai\n",
        "                M=(R*V).sum(dim=2,keepdim=True)/R.sum(dim=2,keepdim=True)\n",
        "                E=(R*(M-V)**2).sum(dim=2,keepdim=True)/R.sum(dim=2,keepdim=True)\n",
        "                cost=(self.Bu[None, :, None, None, None, None]+torch.log(M))*R.sum(dim=2,keepdim=True)\n",
        "                Aj=F.sigmoid((t+1)*(self.Ba[None, :, None, None, None, None]-cost.sum(dim=-1,keepdim=True)))\n",
        "                \n",
        "                # E-step\n",
        "                P=(-((V-M)**2/(2*E)).sum(dim=3,keepdim=True)).exp()/(2*np.pi*E).prod(dim=-1,keepdim=True)\n",
        "                R=Aj*P/(Aj*P).sum(dim=1,keepdim=True)\n",
        "            M=M.view(-1, self.out_channels, w, w, 4, 4)\n",
        "            M=M.view(-1, self.out_channels, w, w, 4, 4).permute(0, 1, 4, 5, 2, 3).contiguous().view(-1, 16*self.out_channels, w,w)\n",
        "            Aj=Aj.view(-1, self.out_channels, w, w)\n",
        "                \n",
        "            M=torch.cat([M, Aj], dim=1)\n",
        "            \n",
        "        else:\n",
        "            w=x.size(2)\n",
        "            num_caps_j=self.out_channels\n",
        "            num_caps_i=self.in_channels*w*w #*k_square\n",
        "            \n",
        "            pose_i=x[:, :-self.in_channels, :, :].view(-1, self.in_channels, 4, \n",
        "                                                       4, x.size(2), x.size(3))\\\n",
        "                      .permute(0, 1, 4, 5, 2, 3).contiguous()\n",
        "            Ai=x[:, -self.in_channels:, :, :].view(-1, 1, num_caps_i, 1)\n",
        "            \n",
        "            V=(pose_i[:, None, :, :, :, :, :] @ self.route_weights[None, :, :, None, None, :, :])\\\n",
        "                      .view(-1, num_caps_j, num_caps_i, 16)\n",
        "            \n",
        "            R=torch.ones(V.size(0), V.size(1), V.size(2), 1).to(device)/num_caps_j\n",
        "            for t in range(self.num_iterations):\n",
        "                # M-step\n",
        "                R=R*Ai\n",
        "                M=(R*V).sum(dim=2,keepdim=True)/R.sum(dim=2,keepdim=True)\n",
        "                E=(R*(M-V)**2).sum(dim=2,keepdim=True)/R.sum(dim=2,keepdim=True)\n",
        "                cost=(self.Bu[None, :, None, None]+torch.log(M))*R.sum(dim=2,keepdim=True)\n",
        "                Aj=F.sigmoid((t+1)*(self.Ba[None, :, None, None]-cost.sum(dim=-1,keepdim=True)))\n",
        "                \n",
        "                # E-step\n",
        "                P=(-((V-M)**2/(2*E)).sum(dim=3,keepdim=True)).exp()/(2*np.pi*E).prod(dim=-1,keepdim=True)\n",
        "                R=Aj*P/(Aj*P).sum(dim=1,keepdim=True)\n",
        "            M=M.view(-1, self.out_channels, 4, 4)\n",
        "            M=M.view(-1, self.out_channels, 4, 4).view(-1, 16*self.out_channels)\n",
        "            Aj=Aj.view(-1, self.out_channels)\n",
        "                \n",
        "            M=torch.cat([M, Aj], dim=1)\n",
        "        return M"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JsDTMMtDuno_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CapsNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CapsNet, self).__init__()\n",
        "        \n",
        "        self.conv1=nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, \n",
        "                             stride=2, padding=2)\n",
        "        \n",
        "        self.primary=CapsLayer(type_=\"primary\", in_channels=32, out_channels=32,\n",
        "                               kernel_size=1, stride=1)\n",
        "        \n",
        "        self.convCaps1=CapsLayer(type_=\"conv\", in_channels=32, out_channels=32, \n",
        "                               kernel_size=3, stride=4)\n",
        "        \n",
        "        self.convCaps2=CapsLayer(type_=\"conv\", in_channels=32, out_channels=32, \n",
        "                               kernel_size=3, stride=1)\n",
        "        \n",
        "        self.classCaps=CapsLayer(type_=\"class\", in_channels=32, out_channels=10)\n",
        "        \n",
        "        self.reconst=nn.Sequential(\n",
        "            nn.Linear(17*10 ,512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 784),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def reconstruction(self, x, y):\n",
        "        recon_images = self.reconst((x*y[:,:,None]).view(-1, 170)).view(-1, 28, 28)\n",
        "        return recon_images\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        l1=F.relu(self.conv1(x))\n",
        "        l2=self.primary(l1)\n",
        "        l3=self.convCaps1(l2)\n",
        "        l4=self.convCaps2(l3)\n",
        "        l5=self.classCaps(l4).view(-1, 10, 17)\n",
        "        \n",
        "        preds=l5[:, :, -1].view(-1, 10)\n",
        "        \n",
        "        return preds, self.reconstruction(l5, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KP76wfPGurD4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CapsLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CapsLoss, self).__init__()\n",
        "        \n",
        "    def forward(self, images, labels, preds, reconst_images):\n",
        "        preds=torch.clamp(preds, min=0.1, max=0.9)\n",
        "        margin_loss=(labels*((0.9-preds)**2) + 0.5*(1-labels)*((preds-0.1)**2)).sum()\n",
        "        \n",
        "        reconst_loss=((images-reconst_images)**2).sum()\n",
        "        return (margin_loss+0.000*reconst_loss)/images.size(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sjuiPHWfutM6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = CapsLoss()\n",
        "net=CapsNet().to(device) #for GPU\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(3):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    count=0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs, reconst = net(inputs, labels)\n",
        "        loss = criterion(inputs, labels, outputs, reconst)\n",
        "        \n",
        "        L=labels.cpu().detach().numpy()\n",
        "        P=outputs.cpu().detach().numpy()\n",
        "        P=P.argmax(axis=-1)\n",
        "        L=L.argmax(axis=-1)\n",
        "        count+=np.array([L[it]==P[it] for it in range(L.shape[0])]).sum()\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 0:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f count: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 100, count / 100))\n",
        "            running_loss = 0.0\n",
        "            count = 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gFGHsdB1gyo3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "dk3NECtpdmgW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}