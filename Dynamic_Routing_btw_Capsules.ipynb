{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Dynamic Routing btw Capsules.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "jUxAYutU5O4w",
        "colab_type": "code",
        "outputId": "1aad723f-cfef-4f1c-c464-11e0c05bfe57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x57ace000 @  0x7f7edd2be2a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n",
            "0.4.1\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7b-J2lx0HuO7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will code **Capsule Networks** in PyTorch. We will mainly be working with MNIST dataset only in this "
      ]
    },
    {
      "metadata": {
        "id": "XMtLvSH0XBGi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torchvision import transforms, datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2iS9HrO2qHHo",
        "colab_type": "code",
        "outputId": "e8aa8df9-d253-4d24-c06f-ab3a610cc00d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def one_hot_transform(labels):\n",
        "    one_hot = torch.zeros(labels.size()+tuple([10])).scatter_(-1, labels, 1)\n",
        "    return one_hot \n",
        "  \n",
        "trainset = datasets.MNIST ( root='../data', train = True, download = True, transform = transforms.Compose([ transforms.ToTensor(), ]),\n",
        "                            target_transform = one_hot_transform)\n",
        "\n",
        "testset = datasets.MNIST ( root='../data', train = False, download = True, transform = transforms.Compose([ transforms.ToTensor(), ]),\n",
        "                            target_transform = one_hot_transform)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader( trainset, batch_size = 128, shuffle = True, num_workers = 4)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader( testset, batch_size = 128, shuffle = False, num_workers = 4)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9TP2rZIWj9tt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CapsuleLayer(nn.Module):\n",
        "    def __init__(self, num_capsules, num_route_nodes, in_channels, out_channels, kernel_size=None, stride=None,\n",
        "                 num_iterations = 3):\n",
        "        super(CapsuleLayer, self).__init__()\n",
        "\n",
        "        self.num_route_nodes = num_route_nodes\n",
        "        self.num_iterations = num_iterations\n",
        "\n",
        "        self.num_capsules = num_capsules\n",
        "\n",
        "        if num_route_nodes != -1:\n",
        "            self.route_weights = nn.Parameter(torch.randn(num_capsules, num_route_nodes, in_channels, out_channels))\n",
        "        else:\n",
        "            self.capsules = nn.ModuleList(\n",
        "                [nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=0) for _ in\n",
        "                 range(num_capsules)])\n",
        "\n",
        "    def squash(self, tensor, dim=-1):\n",
        "        squared_norm = (tensor ** 2).sum(dim=dim, keepdim=True)\n",
        "        scale = squared_norm / (1 + squared_norm)\n",
        "        return scale * tensor / torch.sqrt(squared_norm)\n",
        "      \n",
        "    def softmax(self, tensor, dim = 1):\n",
        "      transposed_input = tensor.transpose(dim, len(tensor.size()) - 1)\n",
        "      softmaxed_output = F.softmax(transposed_input.contiguous().view(-1, transposed_input.size(-1)), dim=-1)\n",
        "      return softmaxed_output.view(*transposed_input.size()).transpose(dim, len(tensor.size()) - 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.num_route_nodes != -1:\n",
        "            priors = x[None, :, :, None, :] @ self.route_weights[:, None, :, :, :]\n",
        "\n",
        "            logits = torch.zeros(*priors.size()).to(device)\n",
        "            for i in range(self.num_iterations):\n",
        "                probs = self.softmax(logits, dim = 2)\n",
        "                outputs = self.squash((probs * priors).sum(dim=2, keepdim=True))\n",
        "\n",
        "                if i != self.num_iterations - 1:\n",
        "                    delta_logits = (priors * outputs).sum(dim=-1, keepdim=True)\n",
        "                    logits = logits + delta_logits\n",
        "        else:\n",
        "            outputs = [capsule(x).view(x.size(0), -1, 1) for capsule in self.capsules]\n",
        "            outputs = torch.cat(outputs, dim=-1)\n",
        "            outputs = self.squash(outputs)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pdqvaG7JnA8p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CapsuleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CapsuleNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 256, kernel_size = 9, stride = 1)\n",
        "        self.primary_capsules = CapsuleLayer(num_capsules = 8, num_route_nodes = -1, in_channels = 256, out_channels = 32,\n",
        "                                             kernel_size = 9, stride = 2)\n",
        "        self.digit_capsules = CapsuleLayer(num_capsules = 10, num_route_nodes = 32 * 6 * 6, in_channels = 8,\n",
        "                                           out_channels = 16)\n",
        "\n",
        "        self.decoder = nn.Sequential( nn.Linear(16 * 10, 512),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Linear(512, 1024),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Linear(1024, 784),\n",
        "                                      nn.Sigmoid()\n",
        "                                    )\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        x = F.relu(self.conv1(x), inplace=True)\n",
        "        x = self.primary_capsules(x)\n",
        "        x = self.digit_capsules(x).squeeze().transpose(0, 1)\n",
        "\n",
        "        classes = (x ** 2).sum(dim=-1) ** 0.5\n",
        "        classes = F.softmax(classes, dim=-1)\n",
        "\n",
        "        reconstructions = self.decoder((x * y[:, :, None]).view(x.size(0), -1))\n",
        "\n",
        "        return classes, reconstructions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mNz6N0eekjYv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CapsLoss(nn.Module):\n",
        "  \n",
        "    def __init__(self):\n",
        "        super(CapsLoss, self).__init__()\n",
        "        self.reconstruction_loss = nn.MSELoss(size_average = False)\n",
        "\n",
        "    def forward(self, images, labels, classes, reconstructions):\n",
        "        left = F.relu(0.9 - classes, inplace = True) ** 2\n",
        "        right = F.relu(classes - 0.1, inplace = True) ** 2\n",
        "\n",
        "        margin_loss = labels * left + 0.5 * (1. - labels) * right\n",
        "        margin_loss = margin_loss.sum()\n",
        "\n",
        "        images = images.view(reconstructions.size()[0], -1)\n",
        "        reconstruction_loss = self.reconstruction_loss(reconstructions, images)\n",
        "\n",
        "        return (margin_loss + 0.0005 * reconstruction_loss) / images.size(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v41ke8qiFA9s",
        "colab_type": "code",
        "outputId": "23585cc4-0be0-48b5-f790-b45f85052c06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = CapsLoss()\n",
        "net = CapsuleNet().to(device) #for GPU\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
        "start_epoch = 0\n",
        "\n",
        "for epoch in range(10):  # fix num-epochs as 10.\n",
        "\n",
        "    # training\n",
        "    net.train()\n",
        "    running_loss = 0.0\n",
        "    count = 0.0\n",
        "    for data in train_loader:\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs, reconst = net(inputs, labels)\n",
        "        loss = criterion(inputs, labels, outputs, reconst)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # statistics\n",
        "        running_loss +=  ( loss.item() * inputs.size(0)) #multiply by the batch size\n",
        "        count += sum(np.argmax(labels.data.cpu().numpy(), 1) == np.argmax(outputs.data.cpu().numpy(), 1)) #the accuracy\n",
        "    \n",
        "    print ( \"epoch num: %d, Train loss: %.5f, Training Accuracy is: %.5f \" % (epoch + 1, running_loss/len(trainset), count/len(trainset)) )\n",
        "    \n",
        "    # testing\n",
        "    net.eval()\n",
        "    running_loss = 0.0\n",
        "    count = 0.0\n",
        "    for data in test_loader:\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        \n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # forward \n",
        "        with torch.no_grad():\n",
        "            outputs, reconst = net(inputs, labels)\n",
        "        loss = criterion(inputs, labels, outputs, reconst)\n",
        "\n",
        "        # statistics\n",
        "        running_loss +=  ( loss.item() * inputs.size(0)) #multiply by the batch size\n",
        "        count += sum(np.argmax(labels.data.cpu().numpy(), 1) == np.argmax(outputs.data.cpu().numpy(), 1)) #the accuracy\n",
        "        \n",
        "    print ( \"epoch num: %d, Test loss: %.5f, Testing Accuracy is: %.5f \" % (epoch + 1, running_loss/len(testset), count/len(testset)) )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch num: 1, Train loss: 0.50010, Training Accuracy is: 0.93923 \n",
            "epoch num: 1, Test loss: 0.47557, Testing Accuracy is: 0.98520 \n",
            "epoch num: 2, Train loss: 0.47196, Training Accuracy is: 0.98695 \n",
            "epoch num: 2, Test loss: 0.46939, Testing Accuracy is: 0.98850 \n",
            "epoch num: 3, Train loss: 0.46689, Training Accuracy is: 0.99197 \n",
            "epoch num: 3, Test loss: 0.46617, Testing Accuracy is: 0.99130 \n",
            "epoch num: 4, Train loss: 0.46416, Training Accuracy is: 0.99435 \n",
            "epoch num: 4, Test loss: 0.46439, Testing Accuracy is: 0.99290 \n",
            "epoch num: 5, Train loss: 0.46237, Training Accuracy is: 0.99625 \n",
            "epoch num: 5, Test loss: 0.46373, Testing Accuracy is: 0.99160 \n",
            "epoch num: 6, Train loss: 0.46089, Training Accuracy is: 0.99718 \n",
            "epoch num: 6, Test loss: 0.46201, Testing Accuracy is: 0.99210 \n",
            "epoch num: 7, Train loss: 0.45976, Training Accuracy is: 0.99785 \n",
            "epoch num: 7, Test loss: 0.46165, Testing Accuracy is: 0.99300 \n",
            "epoch num: 8, Train loss: 0.45892, Training Accuracy is: 0.99842 \n",
            "epoch num: 8, Test loss: 0.46051, Testing Accuracy is: 0.99370 \n",
            "epoch num: 9, Train loss: 0.45818, Training Accuracy is: 0.99865 \n",
            "epoch num: 9, Test loss: 0.46046, Testing Accuracy is: 0.99320 \n",
            "epoch num: 10, Train loss: 0.45768, Training Accuracy is: 0.99880 \n",
            "epoch num: 10, Test loss: 0.45989, Testing Accuracy is: 0.99370 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y76B-TxXhdYn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "4269db88-564d-4a3b-a3cb-05be4f873e7f"
      },
      "cell_type": "code",
      "source": [
        "# now plot the actual data and reconstruction data. \n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plot_loader = torch.utils.data.DataLoader( trainset, batch_size = 4, shuffle = True, num_workers = 4)\n",
        "\n",
        "net.eval() #evaluating\n",
        "\n",
        "for data in plot_loader:\n",
        "  # get the inputs\n",
        "  inputs, labels = data\n",
        "  inputs = inputs.to(device)\n",
        "  labels = labels.to(device)\n",
        "        \n",
        "  # forward + backward + optimize\n",
        "  outputs, reconst = net(inputs, labels)\n",
        "\n",
        "  break #just take the 4 examples\n",
        "\n",
        "X = np.asarray(inputs.data).astype(np.float32)\n",
        "\n",
        "X_recons = np.asarray(reconst.data.view(-1,28,28)).astype(np.float32)\n",
        "\n",
        "\n",
        "for i in range(X.shape[0]):\n",
        " \n",
        "  plt.subplot(X.shape[0], 2, 2*i+1)\n",
        "  plt.imshow(X[i][0], cmap = 'gray')\n",
        "  plt.title('Actual')\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(X.shape[0], 2, 2*i+2)\n",
        "  plt.imshow(X_recons[i], cmap = 'gray')\n",
        "  plt.title(\"ReCons\")\n",
        "  plt.axis('off')\n",
        "  \n",
        "  #plt.subplots_adjust(wspace=0, hspace=0)\n",
        "  plt.gcf().set_size_inches(5, 5)\n",
        "  plt.tight_layout()\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM0AAAFgCAYAAAAYSf3tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAybk2sZW9CQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7ffb417dccf8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "_-OPxwnPLnAW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}